{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e45a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ae_feature_extraction import *\n",
    "\n",
    "# feature_list_expend = encode_feature_extraction(train_data_expend)  # 获得切片后测试集的featurelist\n",
    "# feature_list_test = encode_feature_extraction(test_dataset)  # 获得testdata的featurelist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc7690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_expend = encode_feature_extraction(train_dataset_expend)  # 获得切片后测试集的featurelist\n",
    "feature_list_test = encode_feature_extraction(test_dataset)  # 获得testdata的featurelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c432f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_list_expend=[xx.squeeze() for xx in feature_list_expend]\n",
    "# feature_list_test=[xx.squeeze() for xx in feature_list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3145c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_expend_encoded = AircraftDataset_expend_feature_extraction(df_train, train_label, feature_list_expend,False)\n",
    "train_encoded_loader = DataLoader(\n",
    "    train_dataset_expend_encoded,\n",
    "    batch_size=CFG.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "test_dataset = AircraftDataset_no_expend_feature_extraction(df_train, test_label, feature_list_test)\n",
    "test_encoded_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False)\n",
    "# classifier_in = KMeans(n_clusters=CFG.num_in_feature_classes, random_state=CFG.seed).fit(get_input(test_dataset))\n",
    "model = CustomModel(CFG.ae_hidden_layer*2).to(device)\n",
    "loss_function = CustomLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06c60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_his_unit_in_unit_0(train_loader, test_loader_batch, in_unit_index, folder, RESUME=False):\n",
    "    \"\"\"\n",
    "    传入 in_unit 的feature来获得kernel完成预测\n",
    "    :param train_loader: 含有多个batch, 是字典形式的\n",
    "    :param test_loader_batch: test loader 的一个batch， 是字典形式的\n",
    "    :param in_unit_index: 记录in unit的index\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # last_loss = torch.tensor([1e5], dtype=torch.float).to(CFG.device)\n",
    "    optimizer = getattr(torch.optim, CFG.optimizer)(model.parameters(), lr=CFG.lr)  # 优化器\n",
    "    scheduler = getattr(torch.optim.lr_scheduler, CFG.scheduler)(optimizer, gamma=CFG.sc_Gamma)  # 指数型学习率\n",
    "    start_epoch = -1\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            nn.init.xavier_uniform_(layer.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    if RESUME:\n",
    "        path_checkpoint = folder + '/ckpt_unit_%s.pth' % (str(in_unit_index))  # 断点路径\n",
    "        if os.path.isfile(path_checkpoint):\n",
    "            checkpoint = torch.load(path_checkpoint, map_location=CFG.device)  # 加载断点\n",
    "\n",
    "            model.load_state_dict(checkpoint['net'])  # 加载模型可学习参数\n",
    "\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])  # 加载优化器参数\n",
    "            start_epoch = checkpoint['epoch']  # 设置开始的epoch\n",
    "            scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "        else:\n",
    "            None\n",
    "\n",
    "    for epoch in range(start_epoch + 1, CFG.epoches):\n",
    "        for data in train_loader:\n",
    "            pred_batch = model(data[\"input\"].to(device))\n",
    "            target_batch = data[\"RUL\"].unsqueeze(-1).to(device)\n",
    "            train_data = data[\"input\"].to(device)\n",
    "            test_data = test_loader_batch[\"input\"].to(device)\n",
    "            loss = loss_function(pred_batch, target_batch, train_data, test_data)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        # scheduler.step(loss,last_loss)\n",
    "        # last_loss = loss\n",
    "        if CFG.print_training_process and epoch % 10 == 0:\n",
    "            print(f\"epoch:{epoch}, loss:{loss.item()},lr:{optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
    "            checkpoint = {\n",
    "                \"net\": model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                \"epoch\": epoch,\n",
    "                'scheduler': scheduler.state_dict()\n",
    "            }\n",
    "            if not os.path.isdir(folder):\n",
    "                os.mkdir(folder)\n",
    "            torch.save(checkpoint, folder + '/ckpt_unit_%s.pth' % (str(in_unit_index)))\n",
    "\n",
    "        if loss.mean() < CFG.jump_out_value:\n",
    "            save_model_weights(model, f\"model_in_unit_{in_unit_index}.pt\",\n",
    "                               cp_folder=folder)\n",
    "            break\n",
    "        elif epoch == (CFG.epoches - 1):\n",
    "            print(f\"epoch:{epoch}, loss:{loss.item()}\")\n",
    "            save_model_weights(model, f\"model_in_unit_{in_unit_index}.pt\",\n",
    "                               cp_folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0454821",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.sc_Gamma=0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "476132d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:14339.6103515625,lr:0.09890548353295386\n",
      "epoch:10, loss:6216.92724609375,lr:0.08859803203984777\n",
      "epoch:20, loss:5361.205078125,lr:0.07936477332643059\n",
      "epoch:30, loss:5165.234375,lr:0.07109376021267357\n",
      "epoch:40, loss:5261.55029296875,lr:0.06368471211262068\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-784aaa55bac2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_encoded_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     fit_his_unit_in_unit_0(train_encoded_loader, test_data, idx,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                    \"./model_checkpoints_ae/kernel without classify\", RESUME=False)\n",
      "\u001b[1;32m<ipython-input-6-03678ee49cc7>\u001b[0m in \u001b[0;36mfit_his_unit_in_unit_0\u001b[1;34m(train_loader, test_loader_batch, in_unit_index, folder, RESUME)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_loader_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\yh.wang\\2\\DNN_model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, pred_batch, target_batch, train_data, test_data)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_kernel_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mmyscheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\yh.wang\\2\\DNN_model.py\u001b[0m in \u001b[0;36mget_kernel_loss\u001b[1;34m(self, pred_batch, target_batch, train_data, test_data)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mn_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCFG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mresidual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtarget_batch\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpred_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\yh.wang\\2\\DNN_model.py\u001b[0m in \u001b[0;36mget_kernel\u001b[1;34m(self, train_data, test_data)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mdiag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             diag[idx]=torch.exp(\n\u001b[0m\u001b[0;32m     66\u001b[0m                 \u001b[1;33m-\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, test_data in enumerate(test_encoded_loader):\n",
    "    fit_his_unit_in_unit_0(train_encoded_loader, test_data, idx,\n",
    "                                   \"./model_checkpoints_ae/kernel without classify\", RESUME=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d089726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
