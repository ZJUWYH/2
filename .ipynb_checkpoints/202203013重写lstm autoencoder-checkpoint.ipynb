{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47500804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ae_feature_extraction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8a0ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_expend=AircraftDataset_expend(df_train,train_label,False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f8740d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': tensor([[ 0.9361,  0.3063,  0.2995, -0.7938,  0.5187, -0.2241],\n",
       "         [ 1.0359,  0.4529,  0.3033, -0.4428,  0.3692, -0.0984],\n",
       "         [ 0.7912,  0.2064,  0.8094, -0.5262,  0.3459, -0.4868]]),\n",
       " 'RUL': tensor(256),\n",
       " 'mode': tensor([1., 0.])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_expend[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e303f72",
   "metadata": {},
   "outputs": [],
   "source": [
    " def my_collate(batch): # pad 数据包含字典的哦\n",
    "    # batch contains a list of tuples of structure (sequence, target)\n",
    "    data = [item[\"input\"] for item in batch]\n",
    "    data = pack_sequence(data, enforce_sorted=False)\n",
    "    targets = [item[\"mode\"] for item in batch]\n",
    "    res = {\n",
    "        \"input\": data,\n",
    "        \"mode\": torch.vstack(targets)\n",
    "\n",
    "    }\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b070b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_expend_loader = DataLoader(train_dataset_expend,\n",
    "                                      batch_size=CFG.ae_batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=True,\n",
    "                                      collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33dd2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_data_expend_loader:None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a9b077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = nn.LSTM(6, 8, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21a7d873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.3258, -0.0143, -0.1640,  0.2382, -1.1426,  0.0556],\n",
       "        [ 1.1156,  0.6711,  0.7901, -0.8037,  0.0189, -0.6900],\n",
       "        [ 0.9954, -0.1461,  0.2548,  0.0333,  0.7490,  0.0873],\n",
       "        ...,\n",
       "        [ 1.4203,  1.3406,  1.4889,  1.2865,  1.2579,  1.2962],\n",
       "        [ 1.1696,  1.0011,  1.3395,  1.3062,  1.1791,  1.2962],\n",
       "        [ 1.2384,  1.4490,  1.3823,  1.3548,  1.3825,  1.2976]]), batch_sizes=tensor([512, 512, 512, 511, 509, 509, 508, 506, 504, 503, 501, 500, 496, 494,\n",
       "        492, 490, 488, 488, 488, 482, 480, 479, 476, 476, 475, 475, 474, 469,\n",
       "        465, 462, 462, 462, 459, 459, 456, 453, 451, 449, 446, 442, 440, 437,\n",
       "        430, 426, 422, 419, 417, 413, 413, 411, 409, 409, 404, 402, 400, 397,\n",
       "        396, 393, 393, 392, 389, 388, 385, 382, 380, 377, 375, 373, 372, 371,\n",
       "        369, 367, 366, 365, 361, 356, 353, 350, 350, 350, 346, 346, 345, 342,\n",
       "        341, 337, 335, 332, 327, 324, 320, 320, 319, 317, 317, 315, 315, 312,\n",
       "        308, 308, 305, 302, 297, 295, 295, 292, 290, 287, 286, 284, 282, 279,\n",
       "        276, 274, 272, 269, 262, 261, 259, 255, 254, 253, 252, 249, 248, 247,\n",
       "        244, 242, 240, 238, 236, 235, 234, 234, 232, 230, 228, 227, 225, 221,\n",
       "        219, 218, 215, 214, 210, 208, 202, 201, 200, 199, 199, 197, 194, 191,\n",
       "        189, 186, 186, 183, 183, 180, 179, 178, 176, 174, 168, 164, 162, 161,\n",
       "        159, 157, 156, 154, 153, 150, 148, 147, 147, 146, 144, 143, 142, 141,\n",
       "        138, 137, 136, 135, 130, 127, 125, 123, 120, 117, 115, 114, 113, 111,\n",
       "        110, 108, 108, 107, 105, 104, 103, 103, 102, 102,  99,  99,  98,  98,\n",
       "         98,  97,  97,  96,  96,  95,  93,  93,  93,  93,  93,  93,  93,  93,\n",
       "         91,  91,  88,  87,  86,  86,  84,  82,  82,  82,  80,  78,  74,  74,\n",
       "         73,  73,  73,  73,  71,  71,  70,  70,  70,  69,  69,  69,  68,  67,\n",
       "         65,  65,  65,  65,  65,  65,  65,  65,  64,  63,  63,  63,  63,  60,\n",
       "         57,  57,  57,  56,  54,  53,  52,  52,  52,  52,  50,  48,  48,  48,\n",
       "         47,  47,  45,  44,  44,  44,  44,  43,  43,  43,  42,  41,  40,  40,\n",
       "         40,  39,  38,  38,  38,  38,  38,  38,  37,  36,  36,  35,  34,  34,\n",
       "         33,  32,  31,  31,  30,  30,  29,  28,  27,  27,  27,  26,  26,  25,\n",
       "         25,  25,  25,  25,  24,  23,  23,  23,  23,  23,  23,  23,  23,  23,\n",
       "         22,  21,  21,  21,  20,  20,  20,  20,  19,  18,  18,  18,  18,  18,\n",
       "         18,  18,  18,  18,  18,  18,  16,  16,  16,  15,  15,  15,  15,  15,\n",
       "         15,  15,  15,  14,  14,  14,  14,  14,  14,  14,  13,  13,  13,  13,\n",
       "         13,  13,  13,  13,  12,  12,  12,  12,  12,  12,  11,  11,  11,  11,\n",
       "         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,   9,   9,   9,\n",
       "          9,   9,   9,   9,   8,   8,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   6,   6,   6,   5,   5,   5,   5,   5,   5,   5,   5,\n",
       "          5,   4,   4,   4,   4,   4,   4,   3,   3,   3,   3,   3,   3,   3,\n",
       "          3,   3,   3,   2,   2,   2,   2,   2,   2,   2,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1]), sorted_indices=tensor([473, 169, 313,  28, 401, 226, 414,  58,  22, 250, 481, 452, 101, 369,\n",
       "        468, 322, 316, 400,  11, 453, 267,  38, 126,  37, 144, 143, 244, 205,\n",
       "        270,  24,   5, 437, 157, 196, 420,  62, 215, 185, 222, 225, 241, 223,\n",
       "          0,  15, 354,  90, 261, 175, 428, 359, 123,  93, 403, 192, 127, 444,\n",
       "        115, 334, 499, 289, 227,  53, 333, 162, 303, 284, 148, 287,  76, 379,\n",
       "        204, 415, 251, 109, 100,   1, 200, 217, 179,  85, 218, 419, 108, 489,\n",
       "        155, 208, 263, 340, 493, 366, 416,  19,  42, 342, 280, 328, 113, 300,\n",
       "        406, 396, 381,  83, 184, 221,  86, 353,  70, 116, 363,  79, 201, 357,\n",
       "        177, 140, 492, 408, 165, 283, 132, 360,  10,  23, 105, 137, 103, 469,\n",
       "        258, 174, 343, 254, 111, 252, 178, 470, 345, 134,  96, 459, 337, 219,\n",
       "        271, 393,  72, 394, 234, 383, 398,  99, 166, 199, 149,   7,  55, 212,\n",
       "        315, 377, 312,  27,  77, 237,  74, 308, 206, 418, 443, 110, 202, 413,\n",
       "        509,  17, 330, 462, 117,  30, 325,  44, 286, 336, 122, 112, 411,  48,\n",
       "        150, 220, 154, 317, 412, 442, 433, 173,  25, 167,   8, 488, 402, 152,\n",
       "         80, 352, 373,  64, 497, 131, 121, 305, 168, 292, 386, 203, 138, 274,\n",
       "        297, 306, 239, 160,  87, 142,  18, 475, 496,  56, 417,   9, 382,  66,\n",
       "        362,   2, 350, 268, 390,  78, 388, 508,  81, 236, 249, 118, 194, 156,\n",
       "        182,  20, 172, 479, 344, 439, 231, 502, 487, 273, 389, 410, 195, 409,\n",
       "        484, 426, 189,  98, 164, 387, 365, 213, 378, 466, 299, 429, 385,  50,\n",
       "        323, 170, 133,  95, 440, 451,  46,  88, 281, 230,  49, 399, 193,  60,\n",
       "        465,  75, 467, 425, 247, 504, 151,  31, 257, 364, 188, 107, 262, 232,\n",
       "        248, 255,  73, 318, 278, 210, 370, 483, 321, 454, 296,  82, 446, 375,\n",
       "         16, 211, 349, 298, 464,  61, 430,  21, 404, 329,  67,  13, 159, 310,\n",
       "        327, 431, 288, 191, 304, 358,  71, 441, 207, 505, 163,  65, 135, 153,\n",
       "        395, 503, 500,  40, 347, 407, 161, 120,  94, 346, 476, 392, 275, 380,\n",
       "        197, 245, 421,  51, 264, 124, 427, 501, 302,  43, 423, 246, 331, 490,\n",
       "        460, 506, 445,  33, 448,  47, 326, 480,   4,  84, 181,   6, 171, 356,\n",
       "         26, 324, 295, 187, 498,  45, 397, 471, 335, 147, 309, 216, 332, 243,\n",
       "        119, 190,  32, 367, 368, 136, 351, 198, 253, 510, 235,  97, 130, 277,\n",
       "         29, 290, 319, 374,  89, 272, 372, 461, 477,  54, 114, 458,  91, 285,\n",
       "        260, 449, 125, 436, 491,  36, 486, 233, 276, 238, 128, 348, 228, 339,\n",
       "        279, 485, 314,  41,  63, 494, 376,  57, 511, 457,  12, 450, 307, 145,\n",
       "        371, 338, 146, 256, 259, 507, 294,  92, 438, 455, 282, 224, 472,  69,\n",
       "        456, 482, 391, 102, 104, 265,  68, 141,  14, 474, 422,   3, 229, 240,\n",
       "        463, 341, 320,  59, 405,  52, 106, 495, 293,  34,  35, 209, 186, 435,\n",
       "        139,  39, 478, 434, 158, 129, 311, 176, 180, 424, 355, 384, 269, 361,\n",
       "        291, 432, 242, 214, 447, 301, 183, 266]), unsorted_indices=tensor([ 42,  75, 225, 473, 372,  30, 375, 151, 192, 221, 120,  18, 444, 319,\n",
       "        470,  43, 308, 169, 216,  91, 239, 315,   8, 121,  29, 190, 378, 157,\n",
       "          3, 406, 173, 287, 394, 367, 485, 486, 425,  23,  21, 491, 339, 437,\n",
       "         92, 359, 175, 383, 272, 369, 181, 276, 265, 353, 481,  61, 415, 152,\n",
       "        219, 441,   7, 479, 279, 313,  35, 438, 199, 333, 223, 318, 468, 461,\n",
       "        106, 328, 142, 296, 160, 281,  68, 158, 229, 109, 196, 232, 305, 101,\n",
       "        373,  79, 104, 214, 273, 410,  45, 418, 455,  51, 344, 269, 136, 403,\n",
       "        255, 147,  74,  12, 465, 124, 466, 122, 482, 291,  82,  73, 165, 130,\n",
       "        179,  96, 416,  56, 107, 172, 235, 392, 343, 202, 178,  50, 355, 422,\n",
       "         22,  54, 430, 495, 404, 201, 118, 268, 135, 334, 397, 123, 208, 490,\n",
       "        113, 469, 215,  25,  24, 447, 450, 387,  66, 150, 182, 286, 195, 335,\n",
       "        184,  84, 237,  32, 494, 320, 213, 342,  63, 332, 256, 116, 148, 191,\n",
       "        204,   1, 267, 376, 240, 189, 127,  47, 497, 112, 132,  78, 498, 374,\n",
       "        238, 510, 102,  37, 488, 381, 290, 254, 393, 325,  53, 278, 236, 250,\n",
       "         33, 350, 399, 149,  76, 110, 166, 207,  70,  27, 162, 330,  85, 487,\n",
       "        299, 309, 153, 259, 507,  36, 389,  77,  80, 139, 183, 103,  38,  41,\n",
       "        459,  39,   5,  60, 432, 474, 275, 244, 293, 427, 144, 402, 233, 159,\n",
       "        429, 212, 475,  40, 506, 391,  26, 351, 361, 284, 294, 234,   9,  72,\n",
       "        131, 400, 129, 295, 451, 288, 126, 452, 420,  46, 292,  86, 354, 467,\n",
       "        511,  20, 227, 502,  28, 140, 411, 247, 209, 348, 428, 405, 298, 434,\n",
       "         94, 274, 458, 117,  65, 419, 176,  67, 324,  59, 407, 504, 205, 484,\n",
       "        454, 380, 304, 210, 311, 262,  97, 509, 358,  64, 326, 203, 211, 446,\n",
       "        161, 388, 321, 496, 156,   2, 436, 154,  16, 185, 297, 408, 478, 302,\n",
       "         15, 266, 379, 174, 370, 322,  95, 317, 170, 362, 390,  62,  57, 386,\n",
       "        177, 138, 449, 433,  87, 477,  93, 128, 242, 134, 345, 340, 431, 310,\n",
       "        226, 398, 197, 105,  44, 500, 377, 111, 327,  49, 119, 503, 224, 108,\n",
       "        289, 258,  89, 395, 396,  13, 300, 448, 412, 198, 409, 307, 440, 155,\n",
       "        260,  69, 349, 100, 222, 145, 501, 264, 206, 257, 230, 248, 228, 464,\n",
       "        347, 141, 143, 336,  99, 384, 146, 277,  17,   4, 194,  52, 316, 480,\n",
       "         98, 341, 115, 251, 249, 180, 186, 167,   6,  71,  90, 220, 163,  81,\n",
       "         34, 352, 472, 360, 499, 283, 253, 356,  48, 263, 314, 323, 505, 188,\n",
       "        493, 489, 423,  31, 456, 243, 270, 329, 187, 164,  55, 366, 306, 508,\n",
       "        368, 421, 445, 271,  11,  19, 303, 457, 462, 443, 417, 137, 364, 413,\n",
       "        171, 476, 312, 280, 261, 282,  14, 125, 133, 385, 460,   0, 471, 217,\n",
       "        346, 414, 492, 241, 371,  10, 463, 301, 252, 435, 426, 246, 193,  83,\n",
       "        363, 424, 114,  88, 439, 483, 218, 200, 382,  58, 338, 357, 245, 337,\n",
       "        285, 331, 365, 453, 231, 168, 401, 442]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba9e278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn(1,6)\n",
    "b=torch.randn(2,6)\n",
    "c=torch.randn(4,6)\n",
    "jj=pack_sequence([a,b,c], enforce_sorted=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3196e2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.0864, -0.7225,  0.7398,  0.8515,  0.7736,  0.5773]]),\n",
       " tensor([[ 0.8498, -1.7885,  1.0311,  0.0329, -0.6070,  0.3156],\n",
       "         [-1.3124, -0.6338,  0.1846,  2.2184,  0.4346,  1.7919]]),\n",
       " tensor([[-0.6697,  1.2649, -0.9972, -0.3648,  1.1717, -0.5084],\n",
       "         [ 1.8197, -0.5205,  0.0940,  0.8746, -1.2265,  1.3209],\n",
       "         [ 1.0342, -0.4946,  1.0049, -0.7041,  0.2728, -0.0304],\n",
       "         [ 0.0861, -1.7298,  0.0811,  1.2690, -1.3678,  0.2210]])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a,b,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20474ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.6697,  1.2649, -0.9972, -0.3648,  1.1717, -0.5084],\n",
       "        [ 0.8498, -1.7885,  1.0311,  0.0329, -0.6070,  0.3156],\n",
       "        [ 1.0864, -0.7225,  0.7398,  0.8515,  0.7736,  0.5773],\n",
       "        [ 1.8197, -0.5205,  0.0940,  0.8746, -1.2265,  1.3209],\n",
       "        [-1.3124, -0.6338,  0.1846,  2.2184,  0.4346,  1.7919],\n",
       "        [ 1.0342, -0.4946,  1.0049, -0.7041,  0.2728, -0.0304],\n",
       "        [ 0.0861, -1.7298,  0.0811,  1.2690, -1.3678,  0.2210]]), batch_sizes=tensor([3, 2, 1, 1]), sorted_indices=tensor([2, 1, 0]), unsorted_indices=tensor([2, 1, 0]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d657534e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.0864, -0.7225,  0.7398,  0.8515,  0.7736,  0.5773],\n",
       "          [ 0.8498, -1.7885,  1.0311,  0.0329, -0.6070,  0.3156],\n",
       "          [-0.6697,  1.2649, -0.9972, -0.3648,  1.1717, -0.5084]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [-1.3124, -0.6338,  0.1846,  2.2184,  0.4346,  1.7919],\n",
       "          [ 1.8197, -0.5205,  0.0940,  0.8746, -1.2265,  1.3209]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.0342, -0.4946,  1.0049, -0.7041,  0.2728, -0.0304]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0861, -1.7298,  0.0811,  1.2690, -1.3678,  0.2210]]]),\n",
       " tensor([1, 2, 4]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_packed_sequence(jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71eb0be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.0864, -0.7225,  0.7398,  0.8515,  0.7736,  0.5773],\n",
       "          [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
       "          [-0.6697,  1.2649, -0.9972, -0.3648,  1.1717, -0.5084]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.8197, -0.5205,  0.0940,  0.8746, -1.2265,  1.3209]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0342, -0.4946,  1.0049, -0.7041,  0.2728, -0.0304]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0861, -1.7298,  0.0811,  1.2690, -1.3678,  0.2210]]]),\n",
       " tensor([1, 2, 4]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padd=pad_packed_sequence(jj)\n",
    "padd[0][:,1][0:3]=torch.ones(1,6)\n",
    "padd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2319df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.6697,  1.2649, -0.9972, -0.3648,  1.1717, -0.5084],\n",
       "        [ 0.8498, -1.7885,  1.0311,  0.0329, -0.6070,  0.3156],\n",
       "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
       "        [ 1.8197, -0.5205,  0.0940,  0.8746, -1.2265,  1.3209],\n",
       "        [-1.3124, -0.6338,  0.1846,  2.2184,  0.4346,  1.7919],\n",
       "        [ 1.0342, -0.4946,  1.0049, -0.7041,  0.2728, -0.0304],\n",
       "        [ 0.0861, -1.7298,  0.0811,  1.2690, -1.3678,  0.2210]]), batch_sizes=tensor([3, 2, 1, 1]), sorted_indices=tensor([2, 1, 0]), unsorted_indices=tensor([2, 1, 0]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_padded_sequence(padd[0],padd[1],enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e04254f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0864, -0.7225,  0.7398,  0.8515,  0.7736,  0.5773],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_packed_sequence(jj)[0][:,0][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a472d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(pad_packed_sequence(jj)[1])):\n",
    "    seq_len=pad_packed_sequence(jj)[1][idx]\n",
    "    pad_packed_sequence(jj)[0][:,idx][0:seq_len]=torch.tensor([0.1748,  0.1220, -0.0921, -0.1599, -0.1666,\n",
    "             0.0334])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4eb3f3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PackedSequence(data=tensor([[ 0.0030,  0.0094,  0.0383, -0.0431,  0.1978, -0.0133,  0.1216,  0.1063],\n",
       "         [-0.0094, -0.1159,  0.1722,  0.1106, -0.0955, -0.1755, -0.1033, -0.1458],\n",
       "         [-0.1003,  0.0526,  0.1748,  0.1220, -0.0921, -0.1599, -0.1666,  0.0334],\n",
       "         [ 0.0426,  0.0537,  0.1651,  0.0510, -0.0385, -0.1577, -0.0209, -0.1813],\n",
       "         [-0.0218,  0.0704,  0.1157,  0.2000, -0.1207, -0.1373, -0.2144, -0.0771],\n",
       "         [-0.0321, -0.1124,  0.1821,  0.1278, -0.1189, -0.1968, -0.0931, -0.0620],\n",
       "         [ 0.0393, -0.0977,  0.2715,  0.1302, -0.0698, -0.2452, -0.0377, -0.1871]],\n",
       "        grad_fn=<CatBackward0>), batch_sizes=tensor([3, 2, 1, 1]), sorted_indices=tensor([2, 1, 0]), unsorted_indices=tensor([2, 1, 0])),\n",
       " (tensor([[[-0.1003,  0.0526,  0.1748,  0.1220, -0.0921, -0.1599, -0.1666,\n",
       "             0.0334],\n",
       "           [-0.0218,  0.0704,  0.1157,  0.2000, -0.1207, -0.1373, -0.2144,\n",
       "            -0.0771],\n",
       "           [ 0.0393, -0.0977,  0.2715,  0.1302, -0.0698, -0.2452, -0.0377,\n",
       "            -0.1871]]], grad_fn=<IndexSelectBackward0>),\n",
       "  tensor([[[-0.2219,  0.1310,  0.2909,  0.2405, -0.1818, -0.2678, -0.2419,\n",
       "             0.0575],\n",
       "           [-0.0740,  0.1603,  0.2661,  0.5596, -0.3162, -0.3213, -0.2719,\n",
       "            -0.1058],\n",
       "           [ 0.1336, -0.1789,  0.5511,  0.3276, -0.2416, -0.5418, -0.0522,\n",
       "            -0.2685]]], grad_fn=<IndexSelectBackward0>)))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder1(jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09b31746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1003,  0.0526,  0.1748,  0.1220, -0.0921, -0.1599, -0.1666,\n",
       "            0.0334]]], grad_fn=<TransposeBackward0>),\n",
       " (tensor([[[-0.1003,  0.0526,  0.1748,  0.1220, -0.0921, -0.1599, -0.1666,\n",
       "             0.0334]]], grad_fn=<StackBackward0>),\n",
       "  tensor([[[-0.2219,  0.1310,  0.2909,  0.2405, -0.1818, -0.2678, -0.2419,\n",
       "             0.0575]]], grad_fn=<StackBackward0>)))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder1(a.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a3f823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=encoder1(data[\"input\"])[0]\n",
    "hh=encoder1(data[\"input\"])[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3874108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad=pad_packed_sequence(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cf01c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0299,  0.0404,  0.1215,  ..., -0.1055, -0.0330, -0.0073],\n",
       "          [-0.0299,  0.0404,  0.1215,  ..., -0.1055, -0.0330, -0.0073],\n",
       "          [-0.0929, -0.0676,  0.0348,  ..., -0.0738,  0.0090,  0.1110],\n",
       "          ...,\n",
       "          [-0.0361, -0.2024,  0.1975,  ..., -0.1713, -0.0751, -0.0926],\n",
       "          [-0.0543,  0.0011, -0.0495,  ..., -0.0394,  0.0578,  0.1011],\n",
       "          [-0.0299,  0.0404,  0.1215,  ..., -0.1055, -0.0330, -0.0073]],\n",
       " \n",
       "         [[-0.0222,  0.0281,  0.1070,  ..., -0.1420,  0.0003, -0.0020],\n",
       "          [-0.0222,  0.0281,  0.1070,  ..., -0.1420,  0.0003, -0.0020],\n",
       "          [-0.1822, -0.0236,  0.0440,  ..., -0.1099, -0.0492,  0.2145],\n",
       "          ...,\n",
       "          [-0.0516, -0.1414,  0.1843,  ..., -0.1608, -0.0453, -0.0068],\n",
       "          [-0.0813,  0.0120, -0.0606,  ..., -0.0572,  0.1150,  0.1428],\n",
       "          [-0.0222,  0.0281,  0.1070,  ..., -0.1420,  0.0003, -0.0020]],\n",
       " \n",
       "         [[-0.0935,  0.0041,  0.1951,  ..., -0.1944, -0.1146,  0.0372],\n",
       "          [-0.0935,  0.0041,  0.1951,  ..., -0.1944, -0.1146,  0.0372],\n",
       "          [-0.2040, -0.0665,  0.0375,  ..., -0.0925,  0.0013,  0.2292],\n",
       "          ...,\n",
       "          [-0.0285, -0.0491,  0.1556,  ..., -0.1835, -0.1913, -0.0786],\n",
       "          [-0.1317,  0.0347,  0.0054,  ..., -0.0874,  0.1106,  0.1911],\n",
       "          [-0.0935,  0.0041,  0.1951,  ..., -0.1944, -0.1146,  0.0372]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "        grad_fn=<IndexSelectBackward0>),\n",
       " tensor([290, 236, 138,  27,  68, 312,  66, 173, 153, 139, 190, 345,  39,  92,\n",
       "          27, 287,  98, 164, 142, 224, 129,  95, 410, 190, 314, 154,  65, 169,\n",
       "         441,  52, 164, 107,  57,  71,  19,  19,  44, 327, 337,  15,  85,  41,\n",
       "         224,  75, 163,  63, 114,  70, 159, 112, 116,  76,  20, 265,  47, 173,\n",
       "         140,  40, 412,  21, 111,  97, 305,  41, 149,  87, 139,  93,  28,  32,\n",
       "         200,  88, 180, 103, 168, 111, 250, 169, 136, 197, 152, 134, 100, 206,\n",
       "          67, 235, 201, 143, 114,  50, 282,  46,  35, 276,  83, 115, 184,  53,\n",
       "         119, 175, 236, 382,  28, 189,  28, 190,  19, 106, 231, 238, 165, 186,\n",
       "         160, 213,  47, 269, 199, 164, 131,  59,  83, 146, 161, 276,  76,  44,\n",
       "         336, 270,  42,  13,  52, 147, 191, 116, 185,  87,  55, 189, 145,  15,\n",
       "         194,  27, 142, 321, 326,  38,  37,  62, 252, 173, 159, 108, 152,  86,\n",
       "         157, 230, 130, 309,  13,  90, 144,  83, 261,  87, 119, 192, 174, 153,\n",
       "         146, 458, 116,  66, 128, 154, 187, 280,  12, 195, 186, 235,  12,  67,\n",
       "         129,   4, 204, 302,  16,  64, 106, 120,  57,  89, 271, 112, 130, 123,\n",
       "         308,  77,  55, 174, 236, 196, 165, 146, 244, 316, 166,  88, 230,  19,\n",
       "         102,  98, 172, 118,   7, 303,  60, 236, 234, 182, 157, 202, 296, 291,\n",
       "          32, 295, 426, 265,  42,  26, 113, 126, 105,  43, 178,  53, 134, 168,\n",
       "          43, 144,  24, 292,   7,  60, 319,  77,  74, 109, 105, 132, 403, 242,\n",
       "         186,  54, 187, 103,  36, 107, 188,  36,  45, 282, 105, 228,  76,  28,\n",
       "           3, 340, 137,  10, 315, 182,  49, 125, 145,  80,  43,  52, 102,  42,\n",
       "         216, 113,  34, 191, 252,  45, 162, 251,  89, 266,  52,   8, 146,  19,\n",
       "          35,  64, 101, 144,  98, 116, 211,   4,  75, 260,  89, 146, 144,  38,\n",
       "         167,  61,  90,  12, 170, 451,  42, 171, 356, 157, 102,  52,  22, 101,\n",
       "         359, 116,  65, 163,  70,  90, 215,  93, 164,  74,  60, 265, 266,  62,\n",
       "         162, 182,  37,  42, 227,  22, 216, 187, 127, 186,  82,  85,  42,  98,\n",
       "         138,  55, 151, 200, 283,  11,  65, 195,  88, 277, 191,   9, 139, 197,\n",
       "         107, 119, 226,  57,  56, 374, 102,  38,  49, 151,  50, 100,  40, 171,\n",
       "         118, 247,  80, 206, 139, 178,  10, 116, 146, 119, 135, 124, 136,  29,\n",
       "          80, 181, 179,  86, 206,  63, 177, 112, 356, 435, 152, 272,  95,  20,\n",
       "         208,  84, 192, 123, 123, 159, 155, 165, 423, 242, 226, 140, 166, 234,\n",
       "         306,  77,  27,  75,  12, 110, 121,  75, 277, 116,  97,  90,   8, 155,\n",
       "          14,  16,  44, 310,  34, 127, 115,  88, 155, 165, 270,  72, 100,   6,\n",
       "          71,  45,  39, 115, 388, 344, 101,  34,  29,  39,  46, 183,  74,  47,\n",
       "         164,  22,  97, 111, 117, 110, 367, 188, 186,  62,  32, 471,  27, 142,\n",
       "          80,  47,  14, 128,  69, 403,  29, 102, 122,  42,  43, 126, 153, 231,\n",
       "          74,  44, 193, 226,  41,  19, 141, 148,  63, 266,  85,  75, 126,  85,\n",
       "         109,  88,  73,  35, 135, 164,  54,  39]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8f57e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 525, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"input\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "804c084c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01aeb67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 525, 8])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh.unsqueeze(1).repeat(1,525,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c56f86e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 525, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aemodel(data[\"input\"].to(device))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9988f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
