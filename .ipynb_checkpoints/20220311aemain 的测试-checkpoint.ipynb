{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e45a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ae_feature_extraction import *\n",
    "\n",
    "# feature_list_expend = encode_feature_extraction(train_data_expend)  # 获得切片后测试集的featurelist\n",
    "# feature_list_test = encode_feature_extraction(test_dataset)  # 获得testdata的featurelist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ae6fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_feature_extraction1(instance):\n",
    "    \"\"\"\n",
    "    instance is a 类的实例，含有原有的时间序列数据\n",
    "    return the extracted feature as a list n*num_feature\n",
    "    \"\"\"\n",
    "    aemodel_encode = LSTMAutoEncoder()\n",
    "    aemodel_encode.load_state_dict(torch.load(\"./model_checkpoints_ae/ae/model_ae.pt\", map_location=\"cpu\"))\n",
    "    all_features_list = []\n",
    "    for idx in range(len(instance)):\n",
    "        with torch.no_grad():\n",
    "            ae_result = aemodel_encode.encoder1(instance[idx][\"input\"].unsqueeze(0))[0]#.squeeze(0)\n",
    "            ae_result=aemodel_encode.encoder2(ae_result)[1][0].squeeze()\n",
    "        all_features_list.append(ae_result)\n",
    "    return all_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc7690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_expend1 = encode_feature_extraction1(train_dataset_expend)  # 获得切片后测试集的featurelist_raw\n",
    "feature_list_test1 = encode_feature_extraction1(test_dataset)  # 获得testdata的featurelist_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3145c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_expend_encoded = AircraftDataset_expend_feature_extraction(df_train, train_label, feature_list_expend1)\n",
    "train_encoded_loader = DataLoader(\n",
    "    train_dataset_expend_encoded,\n",
    "    batch_size=CFG.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "test_dataset = AircraftDataset_no_expend_feature_extraction(df_train, test_label, feature_list_test1)\n",
    "test_encoded_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False)\n",
    "# classifier_in = KMeans(n_clusters=CFG.num_in_feature_classes, random_state=CFG.seed).fit(get_input(test_dataset))\n",
    "model = CustomModel(CFG.ae_hidden_layer*2).to(device)\n",
    "loss_function = CustomLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06c60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_his_unit_in_unit_0(train_loader, test_loader_batch, in_unit_index, folder, RESUME=False):\n",
    "    \"\"\"\n",
    "    传入 in_unit 的feature来获得kernel完成预测\n",
    "    :param train_loader: 含有多个batch, 是字典形式的\n",
    "    :param test_loader_batch: test loader 的一个batch， 是字典形式的\n",
    "    :param in_unit_index: 记录in unit的index\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # last_loss = torch.tensor([1e5], dtype=torch.float).to(CFG.device)\n",
    "    optimizer = getattr(torch.optim, CFG.optimizer)(model.parameters(), lr=CFG.lr)  # 优化器\n",
    "    scheduler = getattr(torch.optim.lr_scheduler, CFG.scheduler)(optimizer, gamma=CFG.sc_Gamma)  # 指数型学习率\n",
    "    start_epoch = -1\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            nn.init.xavier_uniform_(layer.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    if RESUME:\n",
    "        path_checkpoint = folder + '/ckpt_unit_%s.pth' % (str(in_unit_index))  # 断点路径\n",
    "        if os.path.isfile(path_checkpoint):\n",
    "            checkpoint = torch.load(path_checkpoint, map_location=CFG.device)  # 加载断点\n",
    "\n",
    "            model.load_state_dict(checkpoint['net'])  # 加载模型可学习参数\n",
    "\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])  # 加载优化器参数\n",
    "            start_epoch = checkpoint['epoch']  # 设置开始的epoch\n",
    "            scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "        else:\n",
    "            None\n",
    "\n",
    "    for epoch in range(start_epoch + 1, CFG.epoches):\n",
    "        for data in train_loader:\n",
    "            pred_batch = model(data[\"input\"].to(device))\n",
    "            target_batch = data[\"RUL\"].unsqueeze(-1).to(device)\n",
    "            train_data = data[\"input\"].to(device)\n",
    "            test_data = test_loader_batch[\"input\"].to(device)\n",
    "            loss = loss_function(pred_batch, target_batch, train_data, test_data)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        # scheduler.step(loss,last_loss)\n",
    "        # last_loss = loss\n",
    "        if CFG.print_training_process and epoch % 10 == 0:\n",
    "            print(f\"epoch:{epoch}, loss:{loss.item()},lr:{optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
    "            checkpoint = {\n",
    "                \"net\": model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                \"epoch\": epoch,\n",
    "                'scheduler': scheduler.state_dict()\n",
    "            }\n",
    "            if not os.path.isdir(folder):\n",
    "                os.mkdir(folder)\n",
    "            torch.save(checkpoint, folder + '/ckpt_unit_%s.pth' % (str(in_unit_index)))\n",
    "\n",
    "        if loss.mean() < CFG.jump_out_value:\n",
    "            save_model_weights(model, f\"model_in_unit_{in_unit_index}.pt\",\n",
    "                               cp_folder=folder)\n",
    "            break\n",
    "        elif epoch == (CFG.epoches - 1):\n",
    "            print(f\"epoch:{epoch}, loss:{loss.item()}\")\n",
    "            save_model_weights(model, f\"model_in_unit_{in_unit_index}.pt\",\n",
    "                               cp_folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0454821",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.sc_Gamma=0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476132d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:12200.6162109375,lr:0.09890548353295386\n",
      "epoch:10, loss:3649.643798828125,lr:0.08859803203984777\n",
      "epoch:20, loss:3174.1259765625,lr:0.07936477332643059\n",
      "epoch:30, loss:3444.789306640625,lr:0.07109376021267357\n",
      "epoch:40, loss:3537.2412109375,lr:0.06368471211262068\n",
      "epoch:50, loss:3310.347900390625,lr:0.05704779919833771\n",
      "epoch:60, loss:3354.708740234375,lr:0.05110255327241894\n",
      "epoch:70, loss:3263.291259765625,lr:0.04577689214409707\n",
      "epoch:80, loss:3327.454345703125,lr:0.041006245680160425\n",
      "epoch:90, loss:3292.71630859375,lr:0.03673277293461932\n",
      "epoch:100, loss:3095.048583984375,lr:0.032904660865335375\n",
      "epoch:110, loss:3598.960693359375,lr:0.029475496135014385\n",
      "epoch:120, loss:3159.05078125,lr:0.026403702380063794\n",
      "epoch:130, loss:3298.459716796875,lr:0.023652036124570106\n",
      "epoch:140, loss:3336.44384765625,lr:0.021187135227685356\n",
      "epoch:150, loss:3198.087646484375,lr:0.018979114389644735\n",
      "epoch:160, loss:3153.134765625,lr:0.017001202812192157\n",
      "epoch:170, loss:3422.08837890625,lr:0.015229419620285088\n",
      "epoch:180, loss:2959.953125,lr:0.013642283109780644\n",
      "epoch:190, loss:3066.548583984375,lr:0.012220550295922724\n",
      "epoch:200, loss:3344.72412109375,lr:0.010946983604827014\n",
      "epoch:210, loss:3119.7822265625,lr:0.009806141879251842\n",
      "epoch:220, loss:3401.90380859375,lr:0.008784193164737667\n",
      "epoch:230, loss:3273.31494140625,lr:0.007868747006270223\n",
      "epoch:240, loss:3338.7470703125,lr:0.007048704222174932\n",
      "epoch:250, loss:3296.40380859375,lr:0.006314122333850078\n",
      "epoch:260, loss:3150.069580078125,lr:0.0056560950197627555\n",
      "epoch:270, loss:2960.8447265625,lr:0.0050666441321668325\n",
      "epoch:280, loss:3218.421875,lr:0.004538622967316654\n",
      "epoch:290, loss:3015.73046875,lr:0.004065629616391608\n",
      "epoch:300, loss:3274.343994140625,lr:0.003641929346568554\n",
      "epoch:310, loss:3479.84033203125,lr:0.0032623850711637693\n",
      "epoch:320, loss:3635.80029296875,lr:0.002922395065840656\n",
      "epoch:330, loss:3104.64306640625,lr:0.0026178371757332912\n",
      "epoch:340, loss:2999.42822265625,lr:0.002345018837033896\n",
      "epoch:350, loss:3044.932861328125,lr:0.0021006323070889344\n",
      "epoch:360, loss:3226.48046875,lr:0.0018817145601982253\n",
      "epoch:370, loss:3515.1279296875,lr:0.0016856113628800264\n",
      "epoch:380, loss:3329.792236328125,lr:0.0015099450930384209\n",
      "epoch:390, loss:3017.1416015625,lr:0.001352585912861505\n",
      "epoch:400, loss:3614.513427734375,lr:0.0012116259459408298\n",
      "epoch:410, loss:3320.002197265625,lr:0.0010853561455266521\n",
      "epoch:420, loss:3306.75146484375,lr:0.0009722455734618267\n",
      "epoch:430, loss:3467.78466796875,lr:0.0008709228385650715\n",
      "epoch:440, loss:3224.247314453125,lr:0.0007801594694162141\n",
      "epoch:450, loss:3091.969970703125,lr:0.0006988550199494087\n",
      "epoch:460, loss:3134.16162109375,lr:0.0006260237272694418\n"
     ]
    }
   ],
   "source": [
    "for idx, test_data in enumerate(test_encoded_loader):\n",
    "    fit_his_unit_in_unit_0(train_encoded_loader, test_data, idx,\n",
    "                                   \"./model_checkpoints_ae/kernel without classify\", RESUME=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d089726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
